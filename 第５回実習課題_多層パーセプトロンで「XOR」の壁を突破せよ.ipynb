{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**🎯目的**"
      ],
      "metadata": {
        "id": "JFjDnCuYoxKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "前回、パーセプトロン（直線1本）では **XOR (排他的論理和)** を分類できないことを確認しました。今回は、パーセプトロンを複数組み合わせた **「多層パーセプトロン（Multi-Layer Perceptron : MLP）」** を構築します。"
      ],
      "metadata": {
        "id": "XCaeOqt5o5pi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "「層を重ねる」＝「視点を増やす」ことで、直線では分けられないデータが分けられるようになる瞬間を体験しましょう。"
      ],
      "metadata": {
        "id": "euGAfXpErBb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**🖊前提知識**"
      ],
      "metadata": {
        "id": "tADHIxXZrMBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **XORゲート**：片方だけが1のとき1を出力する。\n",
        "*  **論理回路の合成**：XORは、NAND, OR, ANDの組み合わせで作れる。\n",
        "*  **隠れ層(Hidden Layer)**：入力層と出力層の間にある層。ここで特徴変換が行われる。\n",
        "\n"
      ],
      "metadata": {
        "id": "h1RFIGktrTFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**【準備】データの作成（XOR）**"
      ],
      "metadata": {
        "id": "zelZluF8sPhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "前回倒せなかったラスボス、XORデータを用意します。"
      ],
      "metadata": {
        "id": "xRSM614ksW-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#入力データ x\n",
        "x = np.array([\n",
        "    [0, 0],\n",
        "    [1, 0],\n",
        "    [0, 1],\n",
        "    [1, 1]\n",
        "])\n",
        "\n",
        "#正解ラベル y (XOR)\n",
        "y_xor = np.array([0, 1, 1, 0])\n",
        "\n",
        "#可視化関数の準備（前回と同じ）\n",
        "def plot_boundary(model_func, x, y, title):\n",
        "    x1 = np.arange(-0.5, 1.5, 0.02)\n",
        "    x2 = np.arange(-0.5, 1.5, 0.02)\n",
        "    xx1, xx2 = np.meshgrid(x1, x2)\n",
        "    grid_x = np.array([xx1.flatten(), xx2.flatten()]).T\n",
        "\n",
        "    #モデル関数を使って予測\n",
        "    pred = model_func(grid_x)\n",
        "\n",
        "    plt.contourf(xx1, xx2, pred.reshape(xx1.shape), alpha=0.2, cmap='bwr')\n",
        "    plt.scatter(x[y==0, 0], x[y==0, 1], c='blue', marker='o', label='0')\n",
        "    plt.scatter(x[y==1, 0], x[y==1, 1], c='red', marker='^', label='1')\n",
        "    plt.title(title)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "print(\"データ準備完了\")"
      ],
      "metadata": {
        "id": "CMHvXGyo6XUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**課題１：部品を作る（NAND, ORゲートの実装）**"
      ],
      "metadata": {
        "id": "6tx5yinUCNbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XORを作るには、「NANDゲート」と「ORゲート」が必要です。前回のANDゲートの実装を参考に、適切な重み w とバイアス b を設定して、それぞれの関数を完成させてください。\n",
        "\n",
        "\n",
        "\n",
        "*   **NAND (Not AND)**：ANDの逆。両方1のときだけ**0**。それ以外は**1**。\n",
        "*   **OR**：どちらかが1なら**1**。両方0のときだけ**0**。\n",
        "\n"
      ],
      "metadata": {
        "id": "qmifeml6CgU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ステップ関数（前回と同じ）\n",
        "\n",
        "\n",
        "\n",
        "#汎用パーセプトロン関数（前回と同じ）\n",
        "\n",
        "\n",
        "\n",
        "#【課題１-１】NANDゲートのパラメータを設定\n",
        "def NAND(x):\n",
        "    #ヒント：AND(w=0.5, 0.5, b=-0.7)の符号を全部逆にすると…？\n",
        "    #重みを負にして、バイアスを正にする\n",
        "    w =\n",
        "    b =\n",
        "    return\n",
        "\n",
        "#【課題１-２】ORゲートのパラメータを設定\n",
        "def OR(x):\n",
        "    #ヒント：足して0を超えればいい（(0, 0)の時だけ負になればいい）\n",
        "    w =\n",
        "    b =\n",
        "    return\n",
        "\n",
        "#ANDゲート（前回作成済み・再掲）\n",
        "def AND(x):\n",
        "    w =\n",
        "    b =\n",
        "    return\n",
        "\n",
        "#テスト\n",
        "print(\"NAND(1,1) =\", NAND(np.array([1, 1]))) #0になればOK\n",
        "print(\"OR(0,0) =\", OR(np.array([0, 0]))) #0になればOK\n",
        "print(\"OR(1,0) =\", OR(np.array([1, 0]))) #1になればOK"
      ],
      "metadata": {
        "id": "mXhkCC9t-I87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**課題２：層を重ねる（XORゲートの合成）**"
      ],
      "metadata": {
        "id": "-wCyIUn1IXSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "作成した部品を組み合わせて、2層のネットワークを作ります。論理回路の知識を使うと、XORは以下のように表せます。"
      ],
      "metadata": {
        "id": "-bO4McF8IiTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$$ XOR(x_1,x_2) = AND(\\NAND(x_1,x_2),\\OR(x_1,x_2)\\)$$"
      ],
      "metadata": {
        "id": "q6QmWBl6IIGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "この構成をコードで表現してください。これが **「2層パーセプトロン」** です。"
      ],
      "metadata": {
        "id": "lW_adnIUJTTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#【課題２】XORのゲートの実装\n",
        "def XOR(x):\n",
        "    #第1層（隠れ層）の処理\n",
        "    s1 =  #ニューロン1\n",
        "    s2 =  #ニューロン2\n",
        "\n",
        "    #第1層の出力をまとめる（形状合わせ）\n",
        "    #s1, s2 はそれぞれ（データ数,）の配列なので、並べて（データ数, 2）にする\n",
        "    layered_input =\n",
        "\n",
        "    #第2層（出力層）の処理\n",
        "    y =\n",
        "\n",
        "    return\n",
        "\n",
        "#テスト\n",
        "print(\"予測:\", XOR(x))\n",
        "print(\"正解:\", y_xor)"
      ],
      "metadata": {
        "id": "Wiz4DiBrJgkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**課題３：決定境界の可視化**"
      ],
      "metadata": {
        "id": "pyyHrHyQLFZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "多層化することで、決定境界がどう変化したか確認しましょう。前回の「直線一本」からどう進化したでしょうか？"
      ],
      "metadata": {
        "id": "6rq-shs-LUns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#【課題３】境界線の可視化（実行するだけ）\n"
      ],
      "metadata": {
        "id": "fM9-OBHuK1fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*実行結果を見て、青と赤が正しく領域分けされていることを確認してください。*"
      ],
      "metadata": {
        "id": "ZBIs6hJ9NFCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**課題４：行列演算による実装（ニューラルネットワークの形式へ）**"
      ],
      "metadata": {
        "id": "0GX3XUO8NQel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "課題２では関数を呼び出しましたが、実際のAIプログラミングでは、全ての重みを **「行列」** にまとめて一気に計算します。これにより、層の数やニューロンの数が増えても数式一本で書けるようになります。"
      ],
      "metadata": {
        "id": "CBSgE27tNcbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2層ネットワークの数式は以下の通りです。\n",
        "\n",
        "\n",
        "\n",
        "1.   **隠れ層**：H = step(X・W<sub>1</sub> + b<sub>1</sub>)\n",
        "2.   **出力層**：Y = step(H・W<sub>2</sub> + b<sub>2</sub>)\n",
        "\n",
        "先ほどの手動パラメータを行列形式に書き直して、クラス `MLP` を完成させてください。\n",
        "\n",
        "\n",
        "\n",
        "*   入力 X：2個\n",
        "*   隠れ層 H：2個 (NANDとORの役割)\n",
        "*   出力層 Y：1個 (ANDの役割)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KK2uLo8eOJc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#【課題４】行列演算版の実装\n",
        "\n",
        "class MLP_Scratch:\n",
        "    def __init__(self):\n",
        "        #第1層の重み (入力2つ → 隠れ2つ)\n",
        "        #行1: NANDの重み, 行2: ORの重み となるように並べる\n",
        "        self.W1 =\n",
        "            #x1に対する重み (NAND用, OR用)\n",
        "            #x2に対する重み (NAND用, OR用)\n",
        "\n",
        "        self.b1 =  #NANDのバイアス, ORのバイアス\n",
        "\n",
        "        #第2層の重み (隠れ2つ → 出力1つ)\n",
        "        #ANDの重み\n",
        "        self.W2 =\n",
        "\n",
        "\n",
        "\n",
        "        self.b2 =  #ANDのバイアス\n",
        "\n",
        "    def forward(self, x):\n",
        "        #1. 隠れ層の計算 (内積 + バイアス)\n",
        "        a1 =\n",
        "        h1 =  #活性化関数\n",
        "\n",
        "        #2. 出力層の計算\n",
        "        a2 =\n",
        "        y =\n",
        "\n",
        "        return  #1次元配列にして返す\n",
        "\n",
        "\n",
        "# 動作確認\n",
        "model = MLP_Scratch()\n",
        "plot_boundary(model.forward, x, y_xor, \"Matrix Implementation\")"
      ],
      "metadata": {
        "id": "j_M1tx8SL5y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**課題５：活性化関数の進化（シグモイド関数）**"
      ],
      "metadata": {
        "id": "PdWHlk60dXmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここまでは0か1かを出力する「ステップ関数」を使ってきましたが、次回の「学習（バックプロパゲーション）」では **微分（傾き）** が必要になります。ステップ関数はカクカクしていて微分できない（傾きが0か無限大になる）ため、学習には不向きです。\n",
        "\n",
        "そこで、なめらかなカーブを描く**シグモイド関数**を実装し、形を確認してください。"
      ],
      "metadata": {
        "id": "P3Si-JGadfgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$"
      ],
      "metadata": {
        "id": "JP3-Nx5EXdMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*ヒント：指数関数e<sup>-x</sup> は `np.exp(-x)` で計算できます。*"
      ],
      "metadata": {
        "id": "ciz4gcK6eyaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#【課題５】シグモイド関数の実装とプロット\n",
        "def sigmoid(x):\n",
        "    #ここに実装\n",
        "    return\n",
        "\n",
        "#解説:\n",
        "#入力が0のとき0.5\n",
        "#入力が大きいと1.0に近づく\n",
        "#入力が小さいと0.0に近づく\n",
        "#この「滑らかさ」のおかげで、次回「誤差逆伝播法」で微分が可能になります\n",
        "\n",
        "#グラフで確認\n",
        "x_seq =\n",
        "y_seq =\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SD53utbGfXnS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}